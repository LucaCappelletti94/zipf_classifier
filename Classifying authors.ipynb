{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A Zipf classifier\n",
    "## Using Zipf and statistics to map books to their authors and periods\n",
    "\n",
    "## Introduction\n",
    "Hello, I'm Luca Cappelletti and here I will show you an example of usage of [ZipfClassifier](https://github.com/LucaCappelletti94/zipf_classifier), a classifier that leverages the assumption that some kind of datasets (texts, [some images](http://www.dcs.warwick.ac.uk/bmvc2007/proceedings/CD-ROM/papers/paper-288.pdf), even [sounds in spoken languages](http://journals.plos.org/plosone/article?id=10.1371/journal.pone.0033993)) follows the [Zipf distribution](https://en.wikipedia.org/wiki/Zipf%27s_law)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How to use this notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is a [Jupyter Notebook](http://jupyter.org/). You can either read it [here on github](https://github.com/LucaCappelletti94/zipf_classifier/blob/master/Classifying%20authors.ipynb) or, **preferably** to enjoy all its aspects, run it on your own computer. Jupyter comes installed with [Anaconda](https://anaconda.org/), to execute it you just need to run the following in your terminal:\n",
    "\n",
    "`jupyter-notebook`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What we will use"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The packages\n",
    "We will use obviously the [ZipfClassifier](https://github.com/LucaCappelletti94/zipf_classifier) and other two packages of mine: [Zipf](https://github.com/LucaCappelletti94/zipf) to create the distributions from the texts and [Dictances](https://github.com/LucaCappelletti94/dictances) for the classifications metrics. If you need to install them just run the following command in your terminal:\n",
    "\n",
    "```pip install zipf dictances zipf_classifier```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from zipf.factories import ZipfFromDir\n",
    "from zipf_classifier import ZipfClassifier\n",
    "from dictances import jensen_shannon, normal_total_variation, kullback_leibler, bhattacharyya, bhattacharyya_coefficient, hellinger"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Additional packages\n",
    "We will also be using some utilities, such as the loading bar `tqdm` and the `requests` package. If you don't have them already you can install them by running:\n",
    "\n",
    "```\n",
    "pip install tqdm requests tabulate\n",
    "```\n",
    "\n",
    "The others packages should be already installed with python by default."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import io\n",
    "import inspect\n",
    "import json\n",
    "import math\n",
    "import os\n",
    "import random\n",
    "import shutil\n",
    "import zipfile\n",
    "from collections import defaultdict\n",
    "from pprint import pprint\n",
    "\n",
    "import requests\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "\n",
    "from pygments import highlight\n",
    "from pygments.lexers import PythonLexer\n",
    "from pygments.formatters import HtmlFormatter\n",
    "from IPython.display import HTML, display\n",
    "import tabulate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Some small helpers\n",
    "Let's make ome small functions to help out loading folders:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dirs(root):\n",
    "    \"\"\"Return subdirectories under a directory.\"\"\"\n",
    "    return [root+\"/\"+d for d in os.listdir(root) if os.path.isdir(root+\"/\"+d)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "and the book folders:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_books(root):\n",
    "    \"\"\"Return all books found under a given root.\"\"\"\n",
    "    return [book[0] for book in os.walk(root) for chapter in book[2][:1] if chapter.endswith('.txt')]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "and the saved zipfs:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_zipfs(root):\n",
    "    \"\"\"Return all zipfs found under a given root.\"\"\"\n",
    "    return [zipfs[0]+\"/\"+zipf for zipfs in os.walk(root) for zipf in zipfs[2] if zipf.endswith('.json')]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Some small helpers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def b(string):\n",
    "    \"\"\"Return a boldified string.\"\"\"\n",
    "    return \"\\033[1m%s\\033[0;0m\"%string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def red(string):\n",
    "    \"\"\"Return a red string.\"\"\"\n",
    "    return \"\\033[0;31m%s\\033[0;0m\"%string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def yellow(string):\n",
    "    \"\"\"Return a yellow string.\"\"\"\n",
    "    return \"\\033[0;33m%s\\033[0;0m\"%string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def green(string):\n",
    "    \"\"\"Return a green string.\"\"\"\n",
    "    return \"\\033[0;32m%s\\033[0;0m\"%string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def success(results, metric):\n",
    "    \"\"\"Show the result of a given test.\"\"\"\n",
    "    successes = results[\"success\"]\n",
    "    total = successes + results[\"failures\"] + results[\"unclassified\"]\n",
    "    percentage = round(successes/total*100,2)\n",
    "    if percentage > 90:\n",
    "        metric_name = green(metric.__name__)\n",
    "    elif percentage > 75:\n",
    "        metric_name = yellow(metric.__name__)\n",
    "    else:\n",
    "        metric_name = red(metric.__name__)\n",
    "    print(\"Success with metric %s: %s\"%(metric_name,b(str(percentage)+\"%\")))\n",
    "    display(HTML(tabulate.tabulate(list(results.items()), tablefmt='html')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_function(function):\n",
    "    \"\"\"Print the source of a given function.\"\"\"\n",
    "    code = inspect.getsource(function)\n",
    "    formatter = HtmlFormatter()\n",
    "    display(HTML('<style type=\"text/css\">{}</style>{}'.format(\n",
    "        formatter.get_style_defs('.highlight'),\n",
    "        highlight(code, PythonLexer(), formatter))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The datasets\n",
    "I've prepared a **datasets** of old famous authors (Mary Shelley, Dumas, Carroll...), available in the repo and downloadable [here](https://github.com/LucaCappelletti94/zipf_classifier/blob/master/dataset.zip?raw=true): the authors are separeted by period and their books are already split into chapters, with extension `.txt`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Retrieving the datasets\n",
    "We download and extract the dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets = {\n",
    "    \"authors\": [\n",
    "        \"authors.zip\"\n",
    "    ],\n",
    "    \"periods\": [\n",
    "        \"periods.1.zip\",\n",
    "        \"periods.2.zip\",\n",
    "        \"periods.3.zip\"\n",
    "    ]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_dataset(filename):\n",
    "    if os.path.exists(filename):\n",
    "        return True\n",
    "    \"\"\"Download a dataset into current folder showing progressbar.\"\"\"\n",
    "    url = \"https://github.com/LucaCappelletti94/zipf_classifier/blob/master/%s?raw=true\"%filename\n",
    "    print(\"Downloading %s from %s\"%(b(filename), url))\n",
    "    # Streaming, so we can iterate over the response.\n",
    "    r = requests.get(url, stream=True)\n",
    "\n",
    "    # Total size in bytes.\n",
    "    total_size = int(r.headers.get('content-length', 0)); \n",
    "    block_size = 1024  * 1024\n",
    "    wrote = 0 \n",
    "    with open(filename, 'wb') as f:\n",
    "        for data in tqdm(r.iter_content(block_size), total=math.ceil(total_size//block_size) , unit='MB', unit_scale=True):\n",
    "            wrote = wrote  + len(data)\n",
    "            f.write(data)\n",
    "    if total_size != 0 and wrote != total_size:\n",
    "        return False\n",
    "    return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_zip(path, name):\n",
    "    print(\"Extracting %s\"%b(path))\n",
    "    zip_ref = zipfile.ZipFile(path, 'r')\n",
    "    zip_ref.extractall(name)\n",
    "    zip_ref.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading \u001b[1mauthors.zip.001\u001b[0;0m from https://github.com/LucaCappelletti94/zipf_classifier/blob/master/authors.zip.001?raw=true\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "412eb0db522e4c5d911751e7f29b265c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/html": [
       "<p>Failed to display Jupyter Widget of type <code>HBox</code>.</p>\n",
       "<p>\n",
       "  If you're reading this message in the Jupyter Notebook or JupyterLab Notebook, it may mean\n",
       "  that the widgets JavaScript is still loading. If this message persists, it\n",
       "  likely means that the widgets JavaScript library is either not installed or\n",
       "  not enabled. See the <a href=\"https://ipywidgets.readthedocs.io/en/stable/user_install.html\">Jupyter\n",
       "  Widgets Documentation</a> for setup instructions.\n",
       "</p>\n",
       "<p>\n",
       "  If you're reading this message in another frontend (for example, a static\n",
       "  rendering on GitHub or <a href=\"https://nbviewer.jupyter.org/\">NBViewer</a>),\n",
       "  it may mean that your frontend doesn't currently support widgets.\n",
       "</p>\n"
      ],
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=9), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Extracting \u001b[1mauthors.zip.001\u001b[0;0m\n",
      "Downloading \u001b[1mperiods.zip.001\u001b[0;0m from https://github.com/LucaCappelletti94/zipf_classifier/blob/master/periods.zip.001?raw=true\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2081d6cb6c7c48a79090023bd7c26d75",
       "version_major": 2,
       "version_minor": 0
      },
      "text/html": [
       "<p>Failed to display Jupyter Widget of type <code>HBox</code>.</p>\n",
       "<p>\n",
       "  If you're reading this message in the Jupyter Notebook or JupyterLab Notebook, it may mean\n",
       "  that the widgets JavaScript is still loading. If this message persists, it\n",
       "  likely means that the widgets JavaScript library is either not installed or\n",
       "  not enabled. See the <a href=\"https://ipywidgets.readthedocs.io/en/stable/user_install.html\">Jupyter\n",
       "  Widgets Documentation</a> for setup instructions.\n",
       "</p>\n",
       "<p>\n",
       "  If you're reading this message in another frontend (for example, a static\n",
       "  rendering on GitHub or <a href=\"https://nbviewer.jupyter.org/\">NBViewer</a>),\n",
       "  it may mean that your frontend doesn't currently support widgets.\n",
       "</p>\n"
      ],
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=47), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Downloading \u001b[1mperiods.zip.002\u001b[0;0m from https://github.com/LucaCappelletti94/zipf_classifier/blob/master/periods.zip.002?raw=true\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eb7dd4fcbcd34363b4001ceba43df3b5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/html": [
       "<p>Failed to display Jupyter Widget of type <code>HBox</code>.</p>\n",
       "<p>\n",
       "  If you're reading this message in the Jupyter Notebook or JupyterLab Notebook, it may mean\n",
       "  that the widgets JavaScript is still loading. If this message persists, it\n",
       "  likely means that the widgets JavaScript library is either not installed or\n",
       "  not enabled. See the <a href=\"https://ipywidgets.readthedocs.io/en/stable/user_install.html\">Jupyter\n",
       "  Widgets Documentation</a> for setup instructions.\n",
       "</p>\n",
       "<p>\n",
       "  If you're reading this message in another frontend (for example, a static\n",
       "  rendering on GitHub or <a href=\"https://nbviewer.jupyter.org/\">NBViewer</a>),\n",
       "  it may mean that your frontend doesn't currently support widgets.\n",
       "</p>\n"
      ],
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=47), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Downloading \u001b[1mperiods.zip.003\u001b[0;0m from https://github.com/LucaCappelletti94/zipf_classifier/blob/master/periods.zip.003?raw=true\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "58d8790fccf4446ca1bc6188b9e4984f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/html": [
       "<p>Failed to display Jupyter Widget of type <code>HBox</code>.</p>\n",
       "<p>\n",
       "  If you're reading this message in the Jupyter Notebook or JupyterLab Notebook, it may mean\n",
       "  that the widgets JavaScript is still loading. If this message persists, it\n",
       "  likely means that the widgets JavaScript library is either not installed or\n",
       "  not enabled. See the <a href=\"https://ipywidgets.readthedocs.io/en/stable/user_install.html\">Jupyter\n",
       "  Widgets Documentation</a> for setup instructions.\n",
       "</p>\n",
       "<p>\n",
       "  If you're reading this message in another frontend (for example, a static\n",
       "  rendering on GitHub or <a href=\"https://nbviewer.jupyter.org/\">NBViewer</a>),\n",
       "  it may mean that your frontend doesn't currently support widgets.\n",
       "</p>\n"
      ],
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=41), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Extracting \u001b[1mperiods.zip.001\u001b[0;0m\n"
     ]
    },
    {
     "ename": "BadZipFile",
     "evalue": "File is not a zip file",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mBadZipFile\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-15-619e8937451e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mchunk\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mchunks\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m         \u001b[0mdownload_dataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchunk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0mextract_zip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchunks\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-14-91c93f0db748>\u001b[0m in \u001b[0;36mextract_zip\u001b[0;34m(path)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mextract_zip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Extracting %s\"\u001b[0m\u001b[0;34m%\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0mzip_ref\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mzipfile\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mZipFile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'r'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m     \u001b[0mzip_ref\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextractall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mzip_ref\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/zipfile.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, file, mode, compression, allowZip64)\u001b[0m\n\u001b[1;32m   1106\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1107\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mmode\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'r'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1108\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_RealGetContents\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1109\u001b[0m             \u001b[0;32melif\u001b[0m \u001b[0mmode\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m'w'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'x'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1110\u001b[0m                 \u001b[0;31m# set the modified flag so central directory gets written\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/zipfile.py\u001b[0m in \u001b[0;36m_RealGetContents\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1173\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mBadZipFile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"File is not a zip file\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1174\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mendrec\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1175\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mBadZipFile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"File is not a zip file\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1176\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdebug\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1177\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mendrec\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mBadZipFile\u001b[0m: File is not a zip file"
     ]
    }
   ],
   "source": [
    "for name, chunks in datasets.items():\n",
    "    for chunk in chunks:\n",
    "        download_dataset(chunk)\n",
    "        extract_zip(chunks, name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Splitting into train and test\n",
    "Let's say we leave 70% to training and 30% to testing. Let's proceed to split the dataset in two:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_percentage = 0.7"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we check if the dataset is already split (this might be a re-run):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_already_split(root):\n",
    "    \"\"\"Return a bool indicating if the dataset has already been split.\"\"\"\n",
    "    split_warns = [\"training\", \"testing\"]\n",
    "    for sub_dir in os.listdir(root):\n",
    "        for split_warn in split_warns:\n",
    "            if split_warn in sub_dir:\n",
    "                return True\n",
    "    return False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we split the dataset's books:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_books(root, percentage):\n",
    "    \"\"\"Split the dataset into training and testing.\"\"\"\n",
    "    min_books = math.inf\n",
    "    for author in get_dirs(root):\n",
    "        books = get_books(author)\n",
    "        min_books = min(min_books, len(books))\n",
    "    for author in get_dirs(root):\n",
    "        books = get_books(author)\n",
    "        random.seed(42) # for reproducibility\n",
    "        random.shuffle(books) # Shuffling books\n",
    "        n = int(min_books*percentage)\n",
    "        training_set, testing_set = books[:n], books[n:] # splitting books into the two partitions\n",
    "        # Moving into respective folders\n",
    "        [shutil.copytree(book, \"%s/training/%s\"%(dataset_name, book[len(root)+1:])) for book in training_set]\n",
    "        [shutil.copytree(book, \"%s/testing/%s\"%(dataset_name, book[len(root)+1:])) for book in testing_set]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we actually run the two functions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if is_already_split(dataset_name):\n",
    "    print(\"I believe I've already split the dataset!\")\n",
    "else:\n",
    "    split_books(dataset_name, training_percentage)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After experimental analysis I've determined that the [Jensen Shannon Divergence](https://en.wikipedia.org/wiki/Jensen%E2%80%93Shannon_divergence) is one of the best metric for this kind of classification, other being the [Hellinger distance](https://en.wikipedia.org/wiki/Hellinger_distance) and the [Bhattacharyya distance](https://en.wikipedia.org/wiki/Bhattacharyya_distance). \n",
    "\n",
    "_A small test to experimentally verify this claim is run in the end of the presentation._\n",
    "\n",
    "#### Reasons for using these distances\n",
    "1. They are defined on distributions that do not necessarily share all events.\n",
    "2. They can be implemented with computational complexity $O(\\min(n,m))$, where $n$ and $m$ are respectively the length of two distributions $P, Q$ when one assumes that the $\\sum_{i\\in P}^n p_i = 1$ and $\\sum_{i\\in Q}^m q_i = 1$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Kullback Leibler Divergence\n",
    "$$\n",
    "    D_{KL}(P,Q) = \\sum_i P(i) \\log{\\frac{P(i)}{Q(i)}}\n",
    "$$\n",
    "The KL divergece is defined for all events in a set $P, Q \\subseteq X$. \n",
    "\n",
    "This forces to define the KL for zipfs only on the subset of the events that are shared beetween the two distributions: $X = P \\cap Q$.\n",
    "\n",
    "This ignores all the information about non-sharec events and it is solved via the Jensen Shannon divergence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_function(kullback_leibler)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Jensen Shannon Divergence\n",
    "$$\n",
    "    JSD(P,Q) = \\frac{1}{2}D(P,M) + \\frac{1}{2}D(Q, M) \\qquad M = \\frac{1}{2}(P+Q)\n",
    "$$\n",
    "\n",
    "The KL divergence is defined for every event in a set $X=P\\cup Q$, it is **symmetric** and has **always a finite value**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Getting the current implementation\n",
    "\n",
    "The current implementation works as follows:\n",
    "\n",
    "Starting from the extended formulation:\n",
    "\n",
    "$$\n",
    "    m_i = \\frac{1}{2}(p_i+q_i), \\quad p_i = \\begin{cases}\n",
    "        p_i & i \\in P\\\\\n",
    "        0 & otherwise\n",
    "    \\end{cases}, \\quad q_i = \\begin{cases}\n",
    "        q_i & i \\in Q\\\\\n",
    "        0 & otherwise\n",
    "    \\end{cases}\n",
    "$$\n",
    "\n",
    "$$\n",
    "    JSD(P,Q) = \\frac{1}{2}\\sum_{i \\in P} p_i \\log{\\frac{p_i}{m_i}} + \\frac{1}{2}\\sum_{j \\in Q} q_j \\log{\\frac{q_j}{m_j}}\n",
    "$$\n",
    "\n",
    "Replacing in the formulation $m_i$:\n",
    "\n",
    "$$\n",
    "    JSD(P,Q) = \\frac{1}{2}\\sum_{i \\in P} p_i \\log{\\frac{p_i}{\\frac{1}{2}(p_i+q_i)}} + \\frac{1}{2}\\sum_{j \\in Q} q_j \\log{\\frac{q_j}{\\frac{1}{2}(p_j+q_j)}}\n",
    "$$\n",
    "\n",
    "Splitting the sums in 3 parts: $i \\in P\\setminus P\\cap Q$, $i \\in P\\cap Q$ and $i \\in Q\\setminus P\\cap Q$.\n",
    "\n",
    "$$\n",
    "    JSD(P,Q) = JSD_1(P,Q) + JSD_2(P,Q) + JSD_3(P,Q)\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\begin{align}\n",
    "    JSD_1(P,Q) &= \\frac{1}{2}\\sum_{i \\in P\\setminus P\\cap Q} p_i \\log{\\frac{p_i}{\\frac{1}{2}(p_i+q_i)}} + \\frac{1}{2}\\sum_{j \\in P\\setminus P\\cap Q} q_j \\log{\\frac{q_j}{\\frac{1}{2}(p_j+q_j)}}\\\\\n",
    "               &= \\frac{1}{2}\\sum_{i \\in P\\setminus P\\cap Q} p_i \\log{\\frac{p_i}{\\frac{1}{2}(p_i+q_i)}}\\\\\n",
    "               &= \\frac{1}{2}\\sum_{i \\in P\\setminus P\\cap Q} p_i \\log{\\frac{p_i}{\\frac{1}{2}p_i}}\\\\\n",
    "               &= \\frac{1}{2}\\sum_{i \\in P\\setminus P\\cap Q} p_i \\log{\\frac{1}{\\frac{1}{2}}}\\\\\n",
    "               &= \\frac{1}{2}\\sum_{i \\in P\\setminus P\\cap Q} p_i \\log{2}\\\\\n",
    "               &= \\frac{1}{2}\\log{2}\\sum_{i \\in P\\setminus P\\cap Q} p_i\\\\\n",
    "\\end{align}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\begin{align}\n",
    "    JSD_2(P,Q) &= \\frac{1}{2}\\sum_{i \\in P\\setminus P\\cap Q} p_i \\log{\\frac{p_i}{\\frac{1}{2}(p_i+q_i)}} + \\frac{1}{2}\\sum_{j \\in P\\setminus P\\cap Q} q_j \\log{\\frac{q_j}{\\frac{1}{2}(p_j+q_j)}}\\\\\n",
    "               &= \\frac{1}{2}\\sum_{i \\in P\\cap Q} p_i \\log{\\frac{p_i}{\\frac{1}{2}(p_i+q_i)}} + q_i \\log{\\frac{q_i}{\\frac{1}{2}(p_i+q_i)}}\\\\\n",
    "               &= \\frac{1}{2}\\sum_{i \\in P\\cap Q} p_i \\log{\\frac{2p_i}{p_i+q_i}} + q_i \\log{\\frac{2q_i}{p_i+q_i}}\\\\\n",
    "\\end{align}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\begin{align}\n",
    "    JSD_3(P,Q) &= \\frac{1}{2}\\log{2}\\sum_{j \\in Q\\setminus P\\cap Q} q_j\\\\\n",
    "\\end{align}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Summing $JSD_1$ and $JSD_3$ we can obtain:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$JSD_1+JSD_3 = \\frac{1}{2}\\log{2}\\left(\\sum_{i \\in P\\setminus P\\cap Q} p_i + \\sum_{j \\in Q\\setminus P\\cap Q} q_j\\right)$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In particular, if $\\sum_{j\\in Q}^m q_j = 1$ and $\\sum_{i\\in P}^n p_i = 1$, we can write:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\begin{align}\n",
    "JSD_1+JSD_3 &= \\frac{1}{2}\\log{2}\\left(2 - \\sum_{i \\in P\\cap Q} p_i - \\sum_{j \\in P\\cap Q} q_j\\right)\\\\\n",
    "            &= \\frac{1}{2}\\log{2}\\left(2 - \\sum_{i \\in P\\cap Q} p_i + q_j\\right)\\\\\n",
    "\\end{align}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Putting all togheter we obtain:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$JSD(P,Q) =  \\frac{1}{2}\\left[\\sum_{i \\in P\\cap Q} \\left(p_i \\log{\\frac{2p_i}{p_i+q_i}} + q_i \\log{\\frac{2q_i}{p_i+q_i}}\\right) + \\log{2}\\left(2 - \\sum_{i \\in P\\cap Q} p_i + q_j\\right)\\right]$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What's marvelous about this semplification is that the computational complexity decrease from a naive literal interpretation of the initial formula of $O(n+m)$ to $O(\\min(n,m))$ simply choosing to iterate over whichever of the two distributions holds less events."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_function(jensen_shannon)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_function(normal_total_variation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_function(bhattacharyya_coefficient)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_function(bhattacharyya)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_function(hellinger)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The options\n",
    "We will use the following options for training and testing. More informations about options customizations is available [here](https://github.com/LucaCappelletti94/zipf)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "options = {}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating the Zipfs\n",
    "We will now convert all the chapters in the dataset into the respective zipf for each option."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_zipfs(paths, factory, test_path):\n",
    "    for data_path in tqdm(paths, unit=' zipf'):\n",
    "        path = \"%s/%s.json\"%(test_path, '/'.join(data_path.split('/')[1:]))\n",
    "        # If the zipf already exists we skip it\n",
    "        if os.path.exists(path):\n",
    "            continue\n",
    "        path_dirs = '/'.join(path.split('/')[:-1])\n",
    "        zipf = factory.run(data_path, ['txt'])\n",
    "        if not zipf.is_empty():\n",
    "            if not os.path.exists(path_dirs):\n",
    "                os.makedirs(path_dirs)\n",
    "            zipf.save(path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We define the paths for zipfs and their sources:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_path = \"%s/training\"%dataset_name\n",
    "testing_path = \"%s/testing\"%dataset_name\n",
    "zipfs_path = '%s/zipfs'%dataset_name\n",
    "\n",
    "print(\"I will print training zipfs from %s,\\ntesting zipfs from %s\\nand save them in %s\"%(b(training_path), b(testing_path), b(zipfs_path)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We create a factory for creating the zipfs objects from files with the options defined above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "factory = ZipfFromDir(options=options)\n",
    "print(\"Created a factory with options %s\"%(factory))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wake up zipfs daemons:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "factory.start_processes()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we create the testing zipfs:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Creating training zipfs in %s\"%(b(training_path)))\n",
    "authors = get_dirs(training_path)\n",
    "print(\"Some of the paths I'm converting are:\")\n",
    "pprint(authors[:10])\n",
    "create_zipfs(authors, factory, zipfs_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And then the training zipfs:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Creating testing zipfs in %s\"%(b(testing_path)))\n",
    "books = get_books(testing_path)\n",
    "print(\"Some of the paths I'm converting are:\")\n",
    "random.seed(42)\n",
    "random.shuffle(books)\n",
    "pprint(books[:10])\n",
    "create_zipfs(books, factory, zipfs_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Slaying daemons:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "factory.close_processes()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Creating the Classifier\n",
    "Now we have rendered the training. Let's run some tests!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we create the classifier with the options set above:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = ZipfClassifier(options)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"We're using a classifier with options %s\"%classifier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_zipfs_path = \"%s/training\"%zipfs_path\n",
    "testing_zipfs_path = \"%s/testing\"%zipfs_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Loading zipfs from %s\"%(b(training_zipfs_path)))\n",
    "loaded = []\n",
    "for zipf in tqdm(get_zipfs(training_zipfs_path)):\n",
    "    author = zipf.split('/')[-1].split('.')[0]\n",
    "    args = zipf, author\n",
    "    loaded.append(args)\n",
    "    classifier.add_zipf(*args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Some of the loaded zipfs and its class:\")\n",
    "for path, cls in loaded[:10]:\n",
    "    print(\"Path: %s, class: %s\"%(b(path), b(cls)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Loading tests from %s\"%(b(testing_zipfs_path)))\n",
    "test_couples = []\n",
    "for zipf in tqdm(get_zipfs(testing_zipfs_path)):\n",
    "    author = zipf.split('/')[-2]\n",
    "    args = zipf, author\n",
    "    test_couples.append(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Some of the loaded zipfs and its class:\")\n",
    "random.seed(42)\n",
    "random.shuffle(test_couples)\n",
    "for path, cls in test_couples[:10]:\n",
    "    print(\"Path: %s, class: %s\"%(b(path), b(cls)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "print(b(\"Testing\"))\n",
    "results = classifier.test(test_couples, jensen_shannon)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "success(results, jensen_shannon)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def metrics_test(classifier, test_couples):\n",
    "    \"\"\"Run test on metrics usable on zipfs.\"\"\"\n",
    "    metrics = [normal_total_variation, kullback_leibler, bhattacharyya, hellinger, jensen_shannon]\n",
    "    for metric in tqdm(metrics, unit='metric'):\n",
    "        results = classifier.test(test_couples, metric)\n",
    "        success(results, metric)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics_test(classifier, test_couples)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
